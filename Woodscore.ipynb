{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc2b5073",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import accuracy_score\n",
    "from scipy import spatial\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity \n",
    "from sklearn.datasets import fetch_20newsgroups\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c60642a",
   "metadata": {},
   "source": [
    "## Computing Matrix Multiplication of two embedding matricies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8e3c3a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define two large embedding matricies\n",
    "\n",
    "matrix_1 = torch.rand(50, 768)\n",
    "matrix_2 = torch.rand(45, 768)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cebb8c2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 45)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix_1 = matrix_1.cpu().detach().numpy()     \n",
    "matrix_2 = matrix_2.cpu().detach().numpy()     \n",
    "cosine_sim = cosine_similarity(matrix_1, matrix_2)\n",
    "cosine_sim.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dd94e3a",
   "metadata": {},
   "source": [
    "## Running on Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1965ff31",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer('all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2089790c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cats = ['alt.atheism', 'sci.space']\n",
    "newsgroups_train = fetch_20newsgroups(subset='train', categories=cats)\n",
    "\n",
    "newsgroups_test = fetch_20newsgroups(subset='test',\n",
    "                                 categories=cats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a351e150",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1073"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(newsgroups_train.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dc3b3977",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute embedding for both lists\n",
    "train= model.encode(newsgroups_train.data, convert_to_tensor=True)\n",
    "test = model.encode(newsgroups_test.data, convert_to_tensor=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "55aaa43d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1073, 713)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix_1 = train.cpu().detach().numpy()     \n",
    "matrix_2 = test.cpu().detach().numpy()     \n",
    "cosine_sim = cosine_similarity(matrix_1, matrix_2)\n",
    "cosine_sim.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ac2d84c",
   "metadata": {},
   "source": [
    "## Finding the Average Cosine Similarity Across First Axis?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e881b09d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 713)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we'd want to find the sum of the top-n for each row\n",
    "cosine_sim[:50].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "38826222",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(713,)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how do we find the sum of only the first \"b\" of each row of array\n",
    "avg_matrix = np.sum(cosine_sim[:50], axis = 0)\n",
    "# sort in place by descending - https://stackoverflow.com/questions/26984414/efficiently-sorting-a-numpy-array-in-descending-order \n",
    "avg_matrix[::-1].sort()\n",
    "\n",
    "avg_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "07ddede4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11.210295"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_matrix[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ead2c6de",
   "metadata": {},
   "source": [
    "## Finding Wood Score across dummy inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3eb30ee8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nWhat we're worried about now is that we need to include p in the sample weights for accuracy... that either means we factor it\\ninto the avg matrix which would be preferrable or to calculate accuracy by hand which I dont like as much...\\n\\n\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "What we're worried about now is that we need to include p in the sample weights for accuracy... that either means we factor it\n",
    "into the avg matrix which would be preferrable or to calculate accuracy by hand which I dont like as much...\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5a0783e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(713,)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newsgroups_test.target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8e2c9655",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = np.zeros((713,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "59c925dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4474053295932679"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(newsgroups_test.target, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "13e18b7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wood Score v1 = 1.152342695842117!\n"
     ]
    }
   ],
   "source": [
    "p_matrix = 15 / avg_matrix\n",
    "accuracies = []\n",
    "for count, value in enumerate(newsgroups_test.target):\n",
    "    accuracy = accuracy_score([value], [int(pred[count])])\n",
    "    p = p_matrix[count]\n",
    "    accuracies.append(accuracy*p)\n",
    "    \n",
    "result = sum(accuracies) / len(accuracies)\n",
    "print(f'Wood Score v1 = {result}!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64a33f63",
   "metadata": {},
   "source": [
    "## What is a good value for \"A\"?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "79fdc8bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nThe main equation that we have to worry about here is - a / sum(max_b of similarity(train/test))\\n\\n\\nCosine similarity takes on values between 0 and 1 meaning that the denomenator will take on a value somewhere between (0, b)\\n\\nFor stability we may want to add a max(sum(max_b), np.eps) to avoid division by 0?\\n'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "The main equation that we have to worry about here is - a / sum(max_b of similarity(train/test))\n",
    "\n",
    "\n",
    "Cosine similarity takes on values between 0 and 1 meaning that the denomenator will take on a value somewhere between (0, b)\n",
    "\n",
    "For stability we may want to add a max(sum(max_b), np.eps) to avoid division by 0?\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42840a81",
   "metadata": {},
   "source": [
    "## How to use sentence transformers for STS???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5fefc02f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "sentences = [\"I'm happy\", \"I'm full of happiness\"]\n",
    "\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "#Compute embedding for both lists\n",
    "embedding_1= model.encode(sentences[0], convert_to_tensor=True)\n",
    "embedding_2 = model.encode(sentences[1], convert_to_tensor=True)\n",
    "\n",
    "test = util.pytorch_cos_sim(embedding_1, embedding_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "25bf46ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_621/4229526483.py:3: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matricesor `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2985.)\n",
      "  res = a_norm @ b_norm.T\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.6003, device='cuda:0')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_norm = embedding_1 / embedding_1.norm()\n",
    "b_norm = embedding_2 / embedding_2.norm()\n",
    "res = a_norm @ b_norm.T\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "570cc7ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.6003, device='cuda:0')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_1@embedding_2.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "abaf3936",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6002568602561951"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "572233e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = model.encode(sentences, convert_to_tensor = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c87b5b81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 384])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9002f0bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#embeddings / embeddings.norm(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b2a404a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.6676, -2.6176,  0.5403],\n",
       "        [-0.4915, -0.7438,  0.5187],\n",
       "        [-1.9908,  1.2999, -0.4224],\n",
       "        [ 1.1458, -0.5736,  1.1171]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.randn(4, 3)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "98b99b84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.9398,  0.1911, -0.3412],\n",
      "        [ 0.9986, -0.4693,  0.0519]])\n",
      "[[-0.93977839  0.1910819  -0.34116521]\n",
      " [ 0.99861783 -0.46929857  0.05190084]]\n"
     ]
    }
   ],
   "source": [
    "a = torch.randn(2, 2)\n",
    "b = torch.randn(3, 2) # different row number, for the fun\n",
    "\n",
    "# Given that cos_sim(u, v) = dot(u, v) / (norm(u) * norm(v))\n",
    "#                          = dot(u / norm(u), v / norm(v))\n",
    "# We fist normalize the rows, before computing their dot products via transposition:\n",
    "a_norm = a / a.norm(dim=1)[:, None]\n",
    "b_norm = b / b.norm(dim=1)[:, None]\n",
    "res = torch.mm(a_norm, b_norm.transpose(0,1))\n",
    "print(res)\n",
    "#  0.9978 -0.9986 -0.9985\n",
    "# -0.8629  0.9172  0.9172\n",
    "\n",
    "# -------\n",
    "# Let's verify with numpy/scipy if our computations are correct:\n",
    "a_n = a.numpy()\n",
    "b_n = b.numpy()\n",
    "res_n = np.zeros((2, 3))\n",
    "for i in range(2):\n",
    "    for j in range(3):\n",
    "        # cos_sim(u, v) = 1 - cos_dist(u, v)\n",
    "        res_n[i, j] = 1 - spatial.distance.cosine(a_n[i], b_n[j])\n",
    "print(res_n)\n",
    "# [[ 0.9978022  -0.99855876 -0.99854881]\n",
    "#  [-0.86285472  0.91716063  0.9172349 ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "184dea32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.6531582474708557"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mean(a, 1)[0].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1347949e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences1 = [\"I'm happy\", \"I'm full of happiness\"]\n",
    "\n",
    "sentences2 = [\"I'm sad\", \"I'm full of\"]\n",
    "\n",
    "embedding_1= model.encode(sentences1, convert_to_tensor=True)\n",
    "embedding_2 = model.encode(sentences2, convert_to_tensor=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "46883f9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[inf, inf],\n",
       "        [inf, inf]], device='cuda:0')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_norm = embedding_1 / embedding_1.norm(dim = 0)\n",
    "b_norm = embedding_2 / embedding_2.norm(dim = 0)\n",
    "res = a_norm @ b_norm.T\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a1473514",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.4390, 0.5458], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "output = F.cosine_similarity(embedding_1, embedding_2, dim = 1)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "369b3c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.tensor([[1,2],[3,4]])\n",
    "b = torch.tensor([[1,2], [4,5], [7,8]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "41ed2b09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 5, 14, 23],\n",
       "        [11, 32, 53]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a@b.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1928e8fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
