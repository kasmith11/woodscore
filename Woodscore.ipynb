{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "cc2b5073",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import accuracy_score\n",
    "from scipy import spatial\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity \n",
    "from sklearn.datasets import fetch_20newsgroups"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c60642a",
   "metadata": {},
   "source": [
    "## Computing Matrix Multiplication of two embedding matricies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "8e3c3a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Define two matricies that we will use to test the computation of the p-matrix which we will use to\n",
    "weight the accuracy downstream\n",
    "\n",
    "Matrix 1 will serve as a \"train\" set while Matrix 2 will serve as a \"test\" set...\n",
    "\"\"\"\n",
    "matrix_1 = torch.rand(5, 768)\n",
    "matrix_2 = torch.rand(3, 768)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "cebb8c2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 5)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Taking the cosine similarity of the two matricies in this order gives us a 3x5 array where we\n",
    "have an array for each sample in \"test\" with the 5 floats in each array the cosine similarity with\n",
    "test...\n",
    "\"\"\"\n",
    "\n",
    "cosine_sim = cosine_similarity(matrix_2, matrix_1)\n",
    "cosine_sim.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "737d6d5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.7520966 , 0.75049555, 0.72056574, 0.7420371 , 0.7596464 ],\n",
       "       [0.76788914, 0.7493172 , 0.75799406, 0.75636005, 0.7686009 ],\n",
       "       [0.77892154, 0.74041355, 0.74213445, 0.75219685, 0.7631999 ]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "38201d8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.7596464 , 0.7520966 , 0.75049555, 0.7420371 , 0.72056574],\n",
       "       [0.7686009 , 0.76788914, 0.75799406, 0.75636005, 0.7493172 ],\n",
       "       [0.77892154, 0.7631999 , 0.75219685, 0.74213445, 0.74041355]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "This solution borrows from the second solution in: https://stackoverflow.com/questions/26984414/efficiently-sorting-a-numpy-array-in-descending-order\n",
    "which gets the array into decending order by ordering the negative of the array and then \n",
    "transforming it back...\n",
    "\n",
    "Dealing with axis: https://stackoverflow.com/questions/40200070/what-does-axis-0-do-in-numpys-sum-function\n",
    "\"\"\"\n",
    "\n",
    "-np.sort(-cosine_sim, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "a312c1c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.7520966 , 0.75049555],\n",
       "       [0.76788914, 0.7493172 ],\n",
       "       [0.77892154, 0.74041355]], dtype=float32)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "We only want the first n values of each array... here we use two as a test of indexing.\n",
    "\n",
    "These are the top-n for each array regarding cosine similarity which we will next sum\n",
    "\"\"\"\n",
    "\n",
    "cosine_sim[:,:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "37331060",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.5025921, 1.5172064, 1.519335 ], dtype=float32)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summed = np.sum(cosine_sim[:, :2], axis = 1)\n",
    "summed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "32abc164",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.15025921, 0.15172064, 0.1519335 ], dtype=float32)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = summed / 10\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "6f7bd879",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.15025921"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dd94e3a",
   "metadata": {},
   "source": [
    "## Running on Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1965ff31",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer('all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2089790c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cats = ['alt.atheism', 'sci.space']\n",
    "newsgroups_train = fetch_20newsgroups(subset='train', categories=cats)\n",
    "\n",
    "newsgroups_test = fetch_20newsgroups(subset='test',\n",
    "                                 categories=cats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a351e150",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1073"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(newsgroups_train.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dc3b3977",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute embedding for both lists\n",
    "train = model.encode(newsgroups_train.data, convert_to_tensor=True).cpu()\n",
    "test = model.encode(newsgroups_test.data, convert_to_tensor=True).cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "55aaa43d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1073, 713)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_sim = cosine_similarity(train, test)\n",
    "cosine_sim.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ac2d84c",
   "metadata": {},
   "source": [
    "## Finding the Average Cosine Similarity Across First Axis?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e881b09d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 713)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we'd want to find the sum of the top-n for each row\n",
    "cosine_sim[:50].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "38826222",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(713,)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how do we find the sum of only the first \"b\" of each row of array\n",
    "avg_matrix = np.sum(cosine_sim[:50], axis = 0)\n",
    "# sort in place by descending - https://stackoverflow.com/questions/26984414/efficiently-sorting-a-numpy-array-in-descending-order \n",
    "avg_matrix[::-1].sort()\n",
    "\n",
    "avg_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "07ddede4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12.471147"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_matrix[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ead2c6de",
   "metadata": {},
   "source": [
    "## Finding Wood Score across dummy inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3eb30ee8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nWhat we're worried about now is that we need to include p in the sample weights for accuracy... that either means we factor it\\ninto the avg matrix which would be preferrable or to calculate accuracy by hand which I dont like as much...\\n\\n\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "What we're worried about now is that we need to include p in the sample weights for accuracy... that either means we factor it\n",
    "into the avg matrix which would be preferrable or to calculate accuracy by hand which I dont like as much...\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5a0783e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(713,)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newsgroups_test.target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8e2c9655",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = np.zeros((713,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "59c925dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4474053295932679"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(newsgroups_test.target, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "13e18b7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wood Score v1 = 1.152342695842117!\n"
     ]
    }
   ],
   "source": [
    "p_matrix = 15 / avg_matrix\n",
    "accuracies = []\n",
    "for count, value in enumerate(newsgroups_test.target):\n",
    "    accuracy = accuracy_score([value], [int(pred[count])])\n",
    "    p = p_matrix[count]\n",
    "    accuracies.append(accuracy*p)\n",
    "    \n",
    "result = sum(accuracies) / len(accuracies)\n",
    "print(f'Wood Score v1 = {result}!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64a33f63",
   "metadata": {},
   "source": [
    "## What is a good value for \"A\"?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "79fdc8bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nThe main equation that we have to worry about here is - a / sum(max_b of similarity(train/test))\\n\\n\\nCosine similarity takes on values between 0 and 1 meaning that the denomenator will take on a value somewhere between (0, b)\\n\\nFor stability we may want to add a max(sum(max_b), np.eps) to avoid division by 0?\\n'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "The main equation that we have to worry about here is - a / sum(max_b of similarity(train/test))\n",
    "\n",
    "\n",
    "Cosine similarity takes on values between 0 and 1 meaning that the denomenator will take on a value somewhere between (0, b)\n",
    "\n",
    "For stability we may want to add a max(sum(max_b), np.eps) to avoid division by 0?\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1928e8fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
